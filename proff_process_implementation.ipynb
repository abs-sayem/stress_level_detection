{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load the TESS Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organize the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the TESS dataset\n",
    "dataset_path = \"dataset/tess_dataset\"\n",
    "\n",
    "# List of all emotions in the dataset (folder names)\n",
    "emotions = os.listdir(dataset_path)\n",
    "\n",
    "# Initialize lists to store features and labels\n",
    "audio_features = []\n",
    "emotion_labels = []\n",
    "\n",
    "# Function to extract features (MFCCs) from an audio file\n",
    "def extract_features(audio_path, sr=22050, n_mfcc=13):\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfcc.T, axis=0)  # Take the mean along time axis\n",
    "\n",
    "# Loop through each emotion folder\n",
    "for emotion in emotions:\n",
    "    emotion_folder = os.path.join(dataset_path, emotion)\n",
    "    \n",
    "    # Loop through each audio file in the folder\n",
    "    for file in os.listdir(emotion_folder):\n",
    "        if file.endswith(\".wav\"):  # Process only .wav files\n",
    "            file_path = os.path.join(emotion_folder, file)\n",
    "            \n",
    "            # Extract features and append them\n",
    "            features = extract_features(file_path)\n",
    "            audio_features.append(features)\n",
    "            \n",
    "            # Append the corresponding emotion label\n",
    "            emotion_labels.append(emotion)\n",
    "\n",
    "# Convert to numpy arrays for training\n",
    "audio_features = np.array(audio_features)\n",
    "emotion_labels = np.array(emotion_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organize and Save the CSV Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as 'processed_tess_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save to a CSV file for easy access\n",
    "dataset = pd.DataFrame(audio_features)\n",
    "dataset['Label'] = emotion_labels\n",
    "dataset.to_csv(\"dataset/processed_tess_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as 'processed_tess_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Organizing the Processed Data for Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (2240, 13)\n",
      "Training Labels Shape: (2240, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Encode labels (convert text labels to numbers)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "emotion_labels_encoded = label_encoder.fit_transform(emotion_labels)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    audio_features, emotion_labels_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# One-hot encode the labels for training\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(f\"Training Features Shape: {X_train.shape}\")\n",
    "print(f\"Training Labels Shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess the Audio Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\OAF_angry: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\OAF_angry'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\OAF_disgust: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\OAF_disgust'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\OAF_Fear: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\OAF_Fear'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\OAF_happy: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\OAF_happy'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\OAF_neutral: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\OAF_neutral'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\OAF_Pleasant_surprise: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\OAF_Pleasant_surprise'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\OAF_Sad: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\OAF_Sad'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\YAF_angry: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\YAF_angry'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\YAF_disgust: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\YAF_disgust'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\YAF_fear: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\YAF_fear'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\YAF_happy: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\YAF_happy'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\YAF_neutral: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\YAF_neutral'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\YAF_pleasant_surprised: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\YAF_pleasant_surprised'\n",
      "Error loading dataset/tess_dataset\\TESS Toronto emotional speech set data\\YAF_sad: [Errno 13] Permission denied: 'dataset/tess_dataset\\\\TESS Toronto emotional speech set data\\\\YAF_sad'\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def extract_features(audio_path, sr=22050, n_mfcc=13):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_path, sr=sr)  # Default method\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {audio_path}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfcc.T, axis=0)\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"dataset/tess_dataset\"\n",
    "features, labels = [], []\n",
    "\n",
    "for label in os.listdir(dataset_path):\n",
    "    for file in os.listdir(os.path.join(dataset_path, label)):\n",
    "        file_path = os.path.join(dataset_path, label, file)\n",
    "        feature = extract_features(file_path)\n",
    "        if feature is not None:  # Skip files that failed to load\n",
    "            features.append(feature)\n",
    "            labels.append(label)\n",
    "\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Shape: (2800, 13)\n"
     ]
    }
   ],
   "source": [
    "#features = np.expand_dims(features, axis=-1)  # Add channel dimension\n",
    "print(f\"Feature Shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Build the CNN+LSTM Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN + LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
    "\n",
    "def create_cnn_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        LSTM(64, return_sequences=False),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')  # Output emotion probabilities\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Model**\n",
    "\n",
    "Here we use-\n",
    "- k-fold cross validation (5 folds) for 100 epoch of each.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Epoch 1/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.3827 - loss: 2.0229 - val_accuracy: 0.8268 - val_loss: 0.5911\n",
      "Epoch 2/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8388 - loss: 0.5209 - val_accuracy: 0.8804 - val_loss: 0.3722\n",
      "Epoch 3/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8611 - loss: 0.3868 - val_accuracy: 0.8893 - val_loss: 0.2986\n",
      "Epoch 4/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8972 - loss: 0.2950 - val_accuracy: 0.9018 - val_loss: 0.2928\n",
      "Epoch 5/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8940 - loss: 0.2882 - val_accuracy: 0.8929 - val_loss: 0.2923\n",
      "Epoch 6/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9173 - loss: 0.2320 - val_accuracy: 0.9214 - val_loss: 0.2361\n",
      "Epoch 7/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9266 - loss: 0.2082 - val_accuracy: 0.9089 - val_loss: 0.2885\n",
      "Epoch 8/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9197 - loss: 0.2141 - val_accuracy: 0.9036 - val_loss: 0.2724\n",
      "Epoch 9/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9224 - loss: 0.2039 - val_accuracy: 0.9393 - val_loss: 0.1995\n",
      "Epoch 10/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9338 - loss: 0.1748 - val_accuracy: 0.9232 - val_loss: 0.2109\n",
      "Epoch 11/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9476 - loss: 0.1446 - val_accuracy: 0.9071 - val_loss: 0.2473\n",
      "Epoch 12/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9549 - loss: 0.1285 - val_accuracy: 0.8821 - val_loss: 0.3437\n",
      "Epoch 13/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9463 - loss: 0.1437 - val_accuracy: 0.9250 - val_loss: 0.2076\n",
      "Epoch 14/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9474 - loss: 0.1461 - val_accuracy: 0.9161 - val_loss: 0.2281\n",
      "Epoch 15/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9591 - loss: 0.1295 - val_accuracy: 0.9196 - val_loss: 0.2169\n",
      "Epoch 16/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9579 - loss: 0.1206 - val_accuracy: 0.9125 - val_loss: 0.2371\n",
      "Epoch 17/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9420 - loss: 0.1443 - val_accuracy: 0.9268 - val_loss: 0.2117\n",
      "Epoch 18/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9544 - loss: 0.1264 - val_accuracy: 0.9232 - val_loss: 0.2275\n",
      "Epoch 19/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9656 - loss: 0.1043 - val_accuracy: 0.9196 - val_loss: 0.2126\n",
      "Fold 1: Loss = 0.1995, Accuracy = 0.9393\n",
      "\n",
      "Fold 2/5\n",
      "Epoch 1/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.3680 - loss: 2.0626 - val_accuracy: 0.8018 - val_loss: 0.6741\n",
      "Epoch 2/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8134 - loss: 0.5642 - val_accuracy: 0.8250 - val_loss: 0.4564\n",
      "Epoch 3/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8753 - loss: 0.3691 - val_accuracy: 0.9089 - val_loss: 0.3341\n",
      "Epoch 4/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.3057 - val_accuracy: 0.8946 - val_loss: 0.3017\n",
      "Epoch 5/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9036 - loss: 0.2629 - val_accuracy: 0.9000 - val_loss: 0.3035\n",
      "Epoch 6/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9210 - loss: 0.2155 - val_accuracy: 0.9161 - val_loss: 0.2425\n",
      "Epoch 7/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9331 - loss: 0.2086 - val_accuracy: 0.9107 - val_loss: 0.2673\n",
      "Epoch 8/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.1895 - val_accuracy: 0.9018 - val_loss: 0.2914\n",
      "Epoch 9/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9325 - loss: 0.1830 - val_accuracy: 0.9089 - val_loss: 0.2589\n",
      "Epoch 10/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.1965 - val_accuracy: 0.9018 - val_loss: 0.2750\n",
      "Epoch 11/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9381 - loss: 0.1695 - val_accuracy: 0.9125 - val_loss: 0.2355\n",
      "Epoch 12/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9476 - loss: 0.1416 - val_accuracy: 0.9054 - val_loss: 0.2755\n",
      "Epoch 13/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9479 - loss: 0.1454 - val_accuracy: 0.9214 - val_loss: 0.2555\n",
      "Epoch 14/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9486 - loss: 0.1296 - val_accuracy: 0.9125 - val_loss: 0.2526\n",
      "Epoch 15/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9371 - loss: 0.1652 - val_accuracy: 0.9214 - val_loss: 0.2394\n",
      "Epoch 16/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9458 - loss: 0.1449 - val_accuracy: 0.9000 - val_loss: 0.2929\n",
      "Epoch 17/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9416 - loss: 0.1424 - val_accuracy: 0.8911 - val_loss: 0.3312\n",
      "Epoch 18/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9479 - loss: 0.1337 - val_accuracy: 0.9161 - val_loss: 0.2565\n",
      "Epoch 19/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9569 - loss: 0.1174 - val_accuracy: 0.9161 - val_loss: 0.2384\n",
      "Epoch 20/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9628 - loss: 0.1020 - val_accuracy: 0.8929 - val_loss: 0.2901\n",
      "Epoch 21/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9471 - loss: 0.1331 - val_accuracy: 0.9214 - val_loss: 0.2226\n",
      "Epoch 22/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.1355 - val_accuracy: 0.9214 - val_loss: 0.2276\n",
      "Epoch 23/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9572 - loss: 0.1094 - val_accuracy: 0.9214 - val_loss: 0.2160\n",
      "Epoch 24/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9703 - loss: 0.0989 - val_accuracy: 0.9214 - val_loss: 0.2396\n",
      "Epoch 25/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9713 - loss: 0.0965 - val_accuracy: 0.9107 - val_loss: 0.2915\n",
      "Epoch 26/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9646 - loss: 0.0958 - val_accuracy: 0.9125 - val_loss: 0.2549\n",
      "Epoch 27/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9665 - loss: 0.0885 - val_accuracy: 0.9268 - val_loss: 0.2296\n",
      "Epoch 28/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9690 - loss: 0.0916 - val_accuracy: 0.9125 - val_loss: 0.2961\n",
      "Epoch 29/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9707 - loss: 0.0828 - val_accuracy: 0.8982 - val_loss: 0.3216\n",
      "Epoch 30/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9692 - loss: 0.0832 - val_accuracy: 0.9321 - val_loss: 0.2189\n",
      "Epoch 31/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9705 - loss: 0.0777 - val_accuracy: 0.9214 - val_loss: 0.2449\n",
      "Epoch 32/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9805 - loss: 0.0522 - val_accuracy: 0.9089 - val_loss: 0.2643\n",
      "Epoch 33/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9780 - loss: 0.0590 - val_accuracy: 0.9107 - val_loss: 0.2543\n",
      "Fold 2: Loss = 0.2160, Accuracy = 0.9214\n",
      "\n",
      "Fold 3/5\n",
      "Epoch 1/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.3788 - loss: 2.0729 - val_accuracy: 0.7571 - val_loss: 0.7489\n",
      "Epoch 2/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8184 - loss: 0.5718 - val_accuracy: 0.8518 - val_loss: 0.4102\n",
      "Epoch 3/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8680 - loss: 0.3766 - val_accuracy: 0.8982 - val_loss: 0.3061\n",
      "Epoch 4/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9036 - loss: 0.2832 - val_accuracy: 0.8696 - val_loss: 0.3160\n",
      "Epoch 5/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9034 - loss: 0.2752 - val_accuracy: 0.8964 - val_loss: 0.2960\n",
      "Epoch 6/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9138 - loss: 0.2535 - val_accuracy: 0.9000 - val_loss: 0.2793\n",
      "Epoch 7/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9136 - loss: 0.2290 - val_accuracy: 0.9161 - val_loss: 0.2177\n",
      "Epoch 8/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9254 - loss: 0.1929 - val_accuracy: 0.8893 - val_loss: 0.3138\n",
      "Epoch 9/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9132 - loss: 0.2172 - val_accuracy: 0.9161 - val_loss: 0.2365\n",
      "Epoch 10/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9141 - loss: 0.2053 - val_accuracy: 0.9125 - val_loss: 0.2408\n",
      "Epoch 11/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9366 - loss: 0.1681 - val_accuracy: 0.9232 - val_loss: 0.2050\n",
      "Epoch 12/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9522 - loss: 0.1345 - val_accuracy: 0.9036 - val_loss: 0.2293\n",
      "Epoch 13/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9480 - loss: 0.1426 - val_accuracy: 0.9143 - val_loss: 0.2072\n",
      "Epoch 14/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9528 - loss: 0.1491 - val_accuracy: 0.9107 - val_loss: 0.2238\n",
      "Epoch 15/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9344 - loss: 0.1614 - val_accuracy: 0.9250 - val_loss: 0.2121\n",
      "Epoch 16/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9450 - loss: 0.1485 - val_accuracy: 0.9054 - val_loss: 0.2278\n",
      "Epoch 17/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9440 - loss: 0.1372 - val_accuracy: 0.9250 - val_loss: 0.2260\n",
      "Epoch 18/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9592 - loss: 0.1181 - val_accuracy: 0.9196 - val_loss: 0.2012\n",
      "Epoch 19/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9547 - loss: 0.1283 - val_accuracy: 0.9196 - val_loss: 0.2246\n",
      "Epoch 20/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9604 - loss: 0.1112 - val_accuracy: 0.9161 - val_loss: 0.2051\n",
      "Epoch 21/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9535 - loss: 0.1130 - val_accuracy: 0.9161 - val_loss: 0.2232\n",
      "Epoch 22/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9637 - loss: 0.1055 - val_accuracy: 0.9214 - val_loss: 0.2108\n",
      "Epoch 23/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9599 - loss: 0.1065 - val_accuracy: 0.9268 - val_loss: 0.1846\n",
      "Epoch 24/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9734 - loss: 0.0764 - val_accuracy: 0.9179 - val_loss: 0.2149\n",
      "Epoch 25/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9618 - loss: 0.0985 - val_accuracy: 0.9214 - val_loss: 0.2076\n",
      "Epoch 26/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9694 - loss: 0.0975 - val_accuracy: 0.9321 - val_loss: 0.1820\n",
      "Epoch 27/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9679 - loss: 0.0823 - val_accuracy: 0.9143 - val_loss: 0.2193\n",
      "Epoch 28/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9738 - loss: 0.0797 - val_accuracy: 0.9107 - val_loss: 0.2616\n",
      "Epoch 29/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9570 - loss: 0.1128 - val_accuracy: 0.9304 - val_loss: 0.1995\n",
      "Epoch 30/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9744 - loss: 0.0713 - val_accuracy: 0.9286 - val_loss: 0.2155\n",
      "Epoch 31/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9734 - loss: 0.0765 - val_accuracy: 0.9196 - val_loss: 0.2269\n",
      "Epoch 32/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9701 - loss: 0.0738 - val_accuracy: 0.9250 - val_loss: 0.2211\n",
      "Epoch 33/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9698 - loss: 0.0802 - val_accuracy: 0.9107 - val_loss: 0.2295\n",
      "Epoch 34/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9812 - loss: 0.0540 - val_accuracy: 0.9214 - val_loss: 0.2131\n",
      "Epoch 35/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9742 - loss: 0.0735 - val_accuracy: 0.9268 - val_loss: 0.1777\n",
      "Epoch 36/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9776 - loss: 0.0572 - val_accuracy: 0.9339 - val_loss: 0.1726\n",
      "Epoch 37/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9773 - loss: 0.0589 - val_accuracy: 0.9250 - val_loss: 0.2366\n",
      "Epoch 38/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9824 - loss: 0.0537 - val_accuracy: 0.9232 - val_loss: 0.2166\n",
      "Epoch 39/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.0453 - val_accuracy: 0.9232 - val_loss: 0.2119\n",
      "Epoch 40/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.0747 - val_accuracy: 0.9196 - val_loss: 0.2665\n",
      "Epoch 41/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9836 - loss: 0.0471 - val_accuracy: 0.9232 - val_loss: 0.2314\n",
      "Epoch 42/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9891 - loss: 0.0374 - val_accuracy: 0.9214 - val_loss: 0.2085\n",
      "Epoch 43/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9836 - loss: 0.0428 - val_accuracy: 0.9000 - val_loss: 0.3479\n",
      "Epoch 44/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9769 - loss: 0.0600 - val_accuracy: 0.9268 - val_loss: 0.2009\n",
      "Epoch 45/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9864 - loss: 0.0410 - val_accuracy: 0.9411 - val_loss: 0.1932\n",
      "Epoch 46/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9708 - loss: 0.0629 - val_accuracy: 0.9268 - val_loss: 0.2549\n",
      "Fold 3: Loss = 0.1726, Accuracy = 0.9339\n",
      "\n",
      "Fold 4/5\n",
      "Epoch 1/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.3484 - loss: 2.0915 - val_accuracy: 0.7696 - val_loss: 0.7378\n",
      "Epoch 2/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8285 - loss: 0.5639 - val_accuracy: 0.8429 - val_loss: 0.4740\n",
      "Epoch 3/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8723 - loss: 0.3795 - val_accuracy: 0.8750 - val_loss: 0.3628\n",
      "Epoch 4/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8852 - loss: 0.3240 - val_accuracy: 0.9036 - val_loss: 0.2866\n",
      "Epoch 5/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9160 - loss: 0.2336 - val_accuracy: 0.8768 - val_loss: 0.3397\n",
      "Epoch 6/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9197 - loss: 0.2210 - val_accuracy: 0.8946 - val_loss: 0.3003\n",
      "Epoch 7/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9149 - loss: 0.2385 - val_accuracy: 0.9107 - val_loss: 0.2562\n",
      "Epoch 8/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9145 - loss: 0.2155 - val_accuracy: 0.9071 - val_loss: 0.2422\n",
      "Epoch 9/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9235 - loss: 0.1862 - val_accuracy: 0.9250 - val_loss: 0.2137\n",
      "Epoch 10/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9406 - loss: 0.1788 - val_accuracy: 0.9250 - val_loss: 0.2056\n",
      "Epoch 11/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9346 - loss: 0.1704 - val_accuracy: 0.9268 - val_loss: 0.2150\n",
      "Epoch 12/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9354 - loss: 0.1707 - val_accuracy: 0.9321 - val_loss: 0.2114\n",
      "Epoch 13/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9499 - loss: 0.1407 - val_accuracy: 0.9214 - val_loss: 0.2246\n",
      "Epoch 14/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9445 - loss: 0.1426 - val_accuracy: 0.9196 - val_loss: 0.2244\n",
      "Epoch 15/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9415 - loss: 0.1431 - val_accuracy: 0.9339 - val_loss: 0.2272\n",
      "Epoch 16/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9454 - loss: 0.1360 - val_accuracy: 0.9196 - val_loss: 0.2160\n",
      "Epoch 17/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9445 - loss: 0.1459 - val_accuracy: 0.9125 - val_loss: 0.2650\n",
      "Epoch 18/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9558 - loss: 0.1221 - val_accuracy: 0.9143 - val_loss: 0.2415\n",
      "Epoch 19/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9496 - loss: 0.1296 - val_accuracy: 0.9196 - val_loss: 0.2533\n",
      "Epoch 20/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9610 - loss: 0.1085 - val_accuracy: 0.9357 - val_loss: 0.2093\n",
      "Fold 4: Loss = 0.2056, Accuracy = 0.9250\n",
      "\n",
      "Fold 5/5\n",
      "Epoch 1/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3497 - loss: 2.1351 - val_accuracy: 0.7857 - val_loss: 0.6940\n",
      "Epoch 2/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7933 - loss: 0.6337 - val_accuracy: 0.8429 - val_loss: 0.4401\n",
      "Epoch 3/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8607 - loss: 0.4081 - val_accuracy: 0.8321 - val_loss: 0.4321\n",
      "Epoch 4/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8823 - loss: 0.3287 - val_accuracy: 0.8839 - val_loss: 0.3017\n",
      "Epoch 5/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9147 - loss: 0.2488 - val_accuracy: 0.8696 - val_loss: 0.3349\n",
      "Epoch 6/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9057 - loss: 0.2574 - val_accuracy: 0.8911 - val_loss: 0.2788\n",
      "Epoch 7/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9220 - loss: 0.2160 - val_accuracy: 0.8679 - val_loss: 0.3358\n",
      "Epoch 8/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9125 - loss: 0.2324 - val_accuracy: 0.9179 - val_loss: 0.2352\n",
      "Epoch 9/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9358 - loss: 0.1919 - val_accuracy: 0.8821 - val_loss: 0.2949\n",
      "Epoch 10/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9458 - loss: 0.1600 - val_accuracy: 0.8804 - val_loss: 0.2951\n",
      "Epoch 11/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9261 - loss: 0.1835 - val_accuracy: 0.9018 - val_loss: 0.2599\n",
      "Epoch 12/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9281 - loss: 0.1859 - val_accuracy: 0.8750 - val_loss: 0.3450\n",
      "Epoch 13/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9193 - loss: 0.2126 - val_accuracy: 0.9036 - val_loss: 0.2359\n",
      "Epoch 14/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9490 - loss: 0.1561 - val_accuracy: 0.8625 - val_loss: 0.3800\n",
      "Epoch 15/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9380 - loss: 0.1671 - val_accuracy: 0.8982 - val_loss: 0.2663\n",
      "Epoch 16/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9524 - loss: 0.1216 - val_accuracy: 0.9125 - val_loss: 0.2426\n",
      "Epoch 17/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9415 - loss: 0.1454 - val_accuracy: 0.9250 - val_loss: 0.2159\n",
      "Epoch 18/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9470 - loss: 0.1299 - val_accuracy: 0.9054 - val_loss: 0.2630\n",
      "Epoch 19/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9638 - loss: 0.1068 - val_accuracy: 0.8714 - val_loss: 0.3377\n",
      "Epoch 20/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.1424 - val_accuracy: 0.8982 - val_loss: 0.2560\n",
      "Epoch 21/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9615 - loss: 0.1089 - val_accuracy: 0.8946 - val_loss: 0.3006\n",
      "Epoch 22/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9626 - loss: 0.1125 - val_accuracy: 0.8875 - val_loss: 0.2932\n",
      "Epoch 23/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9522 - loss: 0.1119 - val_accuracy: 0.8929 - val_loss: 0.2737\n",
      "Epoch 24/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9639 - loss: 0.1050 - val_accuracy: 0.8964 - val_loss: 0.2778\n",
      "Epoch 25/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9593 - loss: 0.1030 - val_accuracy: 0.9036 - val_loss: 0.2850\n",
      "Epoch 26/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9575 - loss: 0.1150 - val_accuracy: 0.9071 - val_loss: 0.2689\n",
      "Epoch 27/200\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9656 - loss: 0.0846 - val_accuracy: 0.8875 - val_loss: 0.2962\n",
      "Fold 5: Loss = 0.2159, Accuracy = 0.9250\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Accuracy: 0.9289 ± 0.0066\n",
      "Average Loss: 0.2019 ± 0.0160\n",
      "\n",
      "Training Final Model on Entire Dataset...\n",
      "Epoch 1/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.4046 - loss: 1.9020\n",
      "Epoch 2/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8551 - loss: 0.4619\n",
      "Epoch 3/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8815 - loss: 0.3367\n",
      "Epoch 4/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9081 - loss: 0.2693\n",
      "Epoch 5/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9080 - loss: 0.2501\n",
      "Epoch 6/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9224 - loss: 0.2186\n",
      "Epoch 7/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9106 - loss: 0.2279\n",
      "Epoch 8/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9299 - loss: 0.1968\n",
      "Epoch 9/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9287 - loss: 0.2073\n",
      "Epoch 10/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9257 - loss: 0.1903\n",
      "Epoch 11/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9332 - loss: 0.1884\n",
      "Epoch 12/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9393 - loss: 0.1627\n",
      "Epoch 13/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9339 - loss: 0.1684\n",
      "Epoch 14/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9317 - loss: 0.1768\n",
      "Epoch 15/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9399 - loss: 0.1489\n",
      "Epoch 16/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9574 - loss: 0.1264\n",
      "Epoch 17/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9656 - loss: 0.1034\n",
      "Epoch 18/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9512 - loss: 0.1305\n",
      "Epoch 19/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9592 - loss: 0.1118\n",
      "Epoch 20/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9568 - loss: 0.1190\n",
      "Epoch 21/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9546 - loss: 0.1148\n",
      "Epoch 22/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9575 - loss: 0.1085\n",
      "Epoch 23/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9671 - loss: 0.0981\n",
      "Epoch 24/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9704 - loss: 0.0882\n",
      "Epoch 25/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.0928\n",
      "Epoch 26/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9593 - loss: 0.1075\n",
      "Epoch 27/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9616 - loss: 0.0995\n",
      "Epoch 28/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9704 - loss: 0.0799\n",
      "Epoch 29/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9571 - loss: 0.1038\n",
      "Epoch 30/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9721 - loss: 0.0716\n",
      "Epoch 31/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9718 - loss: 0.0769\n",
      "Epoch 32/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0486\n",
      "Epoch 33/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9748 - loss: 0.0678\n",
      "Epoch 34/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9780 - loss: 0.0561\n",
      "Epoch 35/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9729 - loss: 0.0649\n",
      "Epoch 36/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9793 - loss: 0.0618\n",
      "Epoch 37/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0525\n",
      "Epoch 38/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9872 - loss: 0.0580\n",
      "Epoch 39/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0392\n",
      "Epoch 40/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0488\n",
      "Epoch 41/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9654 - loss: 0.0955\n",
      "Epoch 42/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.0475\n",
      "Epoch 43/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9873 - loss: 0.0422\n",
      "Epoch 44/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0293\n",
      "Epoch 45/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.0448\n",
      "Epoch 46/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9705 - loss: 0.0746\n",
      "Epoch 47/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9770 - loss: 0.0651\n",
      "Epoch 48/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9810 - loss: 0.0490\n",
      "Epoch 49/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0264\n",
      "Epoch 50/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0387\n",
      "Epoch 51/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.0354\n",
      "Epoch 52/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0355\n",
      "Epoch 53/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0186\n",
      "Epoch 54/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 0.0110\n",
      "Epoch 55/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0071\n",
      "Epoch 56/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9832 - loss: 0.0559\n",
      "Epoch 57/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.0731\n",
      "Epoch 58/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9759 - loss: 0.0578\n",
      "Epoch 59/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0330\n",
      "Epoch 60/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0290\n",
      "Epoch 61/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0109\n",
      "Epoch 62/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.0213\n",
      "Epoch 63/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9916 - loss: 0.0264\n",
      "Epoch 64/200\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved at: models\\final_cnnlstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Number of folds\n",
    "k_folds = 5\n",
    "\n",
    "# Create a directory to save models\n",
    "output_dir = \"models\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Convert labels to categorical\n",
    "unique_labels = list(set(labels))\n",
    "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
    "y_encoded = np.array([label_to_index[label] for label in labels])\n",
    "y_categorical = to_categorical(y_encoded, num_classes=len(unique_labels))\n",
    "\n",
    "# Reshape features for CNN+LSTM\n",
    "features = np.expand_dims(features, axis=-1)  # Add a channel dimension\n",
    "\n",
    "# Initialize K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "fold_accuracy = []\n",
    "fold_loss = []\n",
    "\n",
    "# K-Fold Training\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(features)):\n",
    "    print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    X_train, X_val = features[train_idx], features[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    # Create and compile a new model instance for each fold\n",
    "    model = create_cnn_lstm_model(input_shape=(X_train.shape[1], 1), num_classes=len(unique_labels))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Define Early Stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\",  # Monitor validation loss\n",
    "        patience=10,          # Stop after 10 epochs of no improvement\n",
    "        restore_best_weights=True  # Restore the weights of the best epoch\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200,  # Set a higher max epochs; early stopping will stop it early\n",
    "        batch_size=16,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping],  # Add EarlyStopping callback\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    fold_accuracy.append(accuracy)\n",
    "    fold_loss.append(loss)\n",
    "    print(f\"Fold {fold + 1}: Loss = {loss:.4f}, Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Final Cross-Validation Results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(fold_accuracy):.4f} ± {np.std(fold_accuracy):.4f}\")\n",
    "print(f\"Average Loss: {np.mean(fold_loss):.4f} ± {np.std(fold_loss):.4f}\")\n",
    "\n",
    "# Train Final Model on All Data\n",
    "print(\"\\nTraining Final Model on Entire Dataset...\")\n",
    "final_model = create_cnn_lstm_model(input_shape=(features.shape[1], 1), num_classes=len(unique_labels))\n",
    "final_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train with Early Stopping\n",
    "early_stopping_final = EarlyStopping(\n",
    "    monitor=\"loss\",  # Monitor training loss for the final model\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history_final = final_model.fit(\n",
    "    features, y_categorical,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping_final],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the Final Model\n",
    "final_model_path = os.path.join(output_dir, \"final_cnnlstm_model.h5\")\n",
    "final_model.save(final_model_path)\n",
    "print(f\"Final model saved at: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Integrate ASR (Whisper)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error transcribing dataset/test_data/OAF_back_angry.wav: [WinError 2] The system cannot find the file specified\n",
      "Transcribed Text: Transcription is not possible\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    try:\n",
    "        # Load the Whisper model\n",
    "        model = whisper.load_model(\"base\")\n",
    "        \n",
    "        # Attempt to transcribe the audio\n",
    "        result = model.transcribe(audio_path)\n",
    "        return result['text']\n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully\n",
    "        print(f\"Error transcribing {audio_path}: {e}\")\n",
    "        return \"Transcription is not possible\"\n",
    "\n",
    "# Example transcription\n",
    "text = transcribe_audio(\"dataset/test_data/OAF_back_angry.wav\")\n",
    "print(\"Transcribed Text:\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Process with LLM (e.g., GPT-4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m text \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Predict stress level\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m stress_level \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_stress_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43memotion_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Stress Level:\u001b[39m\u001b[38;5;124m\"\u001b[39m, stress_level)\n",
      "Cell \u001b[1;32mIn[35], line 18\u001b[0m, in \u001b[0;36mpredict_stress_level\u001b[1;34m(emotion_scores, text)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mPredicts the stress level based on emotion scores and text input using GPT.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124mGiven the following emotion scores and text, determine the stress level on a scale from 1 to 9:\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124mEmotion Scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00memotion_scores\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124mProvide the stress level only as an integer.\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4.o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#max_tokens=10\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip())\n",
      "File \u001b[1;32md:\\git_projects\\stress_level_detection\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:278\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Missing required arguments; Expected either ('model' and 'prompt') or ('model', 'prompt' and 'stream') arguments to be given"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "api_key = \"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\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Set your OpenAI API key\n",
    "#openai.api_key = \"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\"\n",
    "\n",
    "def predict_stress_level(emotion_scores, text):\n",
    "    \"\"\"\n",
    "    Predicts the stress level based on emotion scores and text input using GPT.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Given the following emotion scores and text, determine the stress level on a scale from 1 to 9:\n",
    "    Emotion Scores: {emotion_scores}\n",
    "    Text: {text}\n",
    "    Provide the stress level only as an integer.\n",
    "    \"\"\"\n",
    "    response = client.completions.create(\n",
    "        engine=\"gpt-4.o\",\n",
    "        prompt=prompt,\n",
    "        #stream=False\n",
    "        max_tokens=10\n",
    "    )\n",
    "    return int(response.choices[0].text.strip())\n",
    "\n",
    "# Example usage\n",
    "emotion_scores = {\n",
    "    'Angry': 0.3,\n",
    "    'Disgust': 0.1,\n",
    "    'Fear': 0.4,\n",
    "    'Happy': 0.1,\n",
    "    'Neutral': 0.2,\n",
    "    'Pleasant_Surprise': 0.05,\n",
    "    'Sad': 0.25\n",
    "}\n",
    "\n",
    "# Replace this with actual transcribed text from Whisper or other ASR\n",
    "text = text\n",
    "\n",
    "# Predict stress level\n",
    "stress_level = predict_stress_level(emotion_scores, text)\n",
    "print(\"Predicted Stress Level:\", stress_level)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
